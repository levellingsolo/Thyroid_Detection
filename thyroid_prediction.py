# -*- coding: utf-8 -*-
"""Thyroid_Prediction_Clg_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tHvPlIWYODb9hSU0HsExn8h6esqK21BR
"""

#importing the dependencies
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

#importing the models
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

#Load the dataset into pandas dataframe
thyroid_df = pd.read_csv('/content/drive/MyDrive/Datasets/hypothyroid.csv')

thyroid_df.head(1000)

thyroid_df = thyroid_df.drop(columns=['referral source', 'TBG'], axis=1)

thyroid_df.head()

thyroid_df.shape



thyroid_df.info()



"""#Label encoding

leaving numerical columns for label encoding and then after we concatenate them
"""

numerical_col = thyroid_df[['age', 'TSH', 'T3', 'TT4', 'T4U', 'FTI']]
thyroid_df = thyroid_df.drop(columns=['age', 'TSH', 'T3', 'TT4 measured', 'TT4', 'T4U', 'FTI'])

numerical_col.head()

thyroid_df.head()

#label encoding
label_encoder = LabelEncoder()
for column in thyroid_df.columns:
    thyroid_df[column]=label_encoder.fit_transform(thyroid_df[column])

thyroid_df.head()

"""#handling ? values of numerical_columns"""

# for TSH column
fig, ax = plt.subplots(figsize=(10,10))
sns.histplot(numerical_col['TSH'], kde=True, ax=ax)

# Replace '?' with NaN
numerical_col['TSH'].replace('?', np.nan, inplace=True)

# Convert non-numeric values to NaN
numerical_col['TSH'] = pd.to_numeric(numerical_col['TSH'], errors='coerce')

# Fill missing values in 'TSH' with the mean of the column
median_value = numerical_col['TSH'].median()
numerical_col['TSH'] = numerical_col['TSH'].fillna(median_value)

fig, ax = plt.subplots(figsize=(10,10))
sns.histplot(numerical_col['TSH'], kde=True, ax=ax)

# for T3 column
fig, ax = plt.subplots(figsize=(50,10))
sns.histplot(numerical_col['T3'], kde=True, ax=ax)

# Replace '?' with NaN
numerical_col['T3'].replace('?', np.nan, inplace=True)

# Convert non-numeric values to NaN
numerical_col['T3'] = pd.to_numeric(numerical_col['T3'], errors='coerce')

# Fill missing values in 'T3' with the mean of the column
median_value = numerical_col['T3'].median()
numerical_col['T3'] = numerical_col['T3'].fillna(median_value)

fig, ax = plt.subplots(figsize=(50,10))
sns.histplot(numerical_col['T3'], kde=True, ax=ax)

# for TT4 column
fig, ax = plt.subplots(figsize=(10,10))
sns.histplot(numerical_col['TT4'], kde=True, ax=ax)

# Replace '?' with NaN
numerical_col['TT4'].replace('?', np.nan, inplace=True)

# Convert non-numeric values to NaN
numerical_col['TT4'] = pd.to_numeric(numerical_col['TT4'], errors='coerce')

# Fill missing values in 'TT4' with the mean of the column
median_value = numerical_col['TT4'].median()
numerical_col['TT4'] = numerical_col['TT4'].fillna(median_value)

fig, ax = plt.subplots(figsize=(10,10))
sns.histplot(numerical_col['TT4'], kde=True, ax=ax)

# for T4U column
fig, ax = plt.subplots(figsize=(10,10))
sns.histplot(numerical_col['T4U'], kde=True, ax=ax)

# Replace '?' with NaN
numerical_col['T4U'].replace('?', np.nan, inplace=True)

# Convert non-numeric values to NaN
numerical_col['T4U'] = pd.to_numeric(numerical_col['T4U'], errors='coerce')

# Fill missing values in 'T4U' with the mean of the column
median_value = numerical_col['T4U'].median()
numerical_col['T4U'] = numerical_col['T4U'].fillna(median_value)

fig, ax = plt.subplots(figsize=(10,10))
sns.histplot(numerical_col['T4U'], kde=True, ax=ax)

# for FTI column
fig, ax = plt.subplots(figsize=(10,10))
sns.histplot(numerical_col['T4U'], kde=True, ax=ax)

# Replace '?' with NaN
numerical_col['FTI'].replace('?', np.nan, inplace=True)

# Convert non-numeric values to NaN
numerical_col['FTI'] = pd.to_numeric(numerical_col['FTI'], errors='coerce')

# Fill missing values in 'FTI' with the mean of the column
median_value = numerical_col['FTI'].median()
numerical_col['FTI'] = numerical_col['FTI'].fillna(median_value)

fig, ax = plt.subplots(figsize=(10,10))
sns.histplot(numerical_col['T4U'], kde=True, ax=ax)

numerical_col.head()

numerical_col.shape, thyroid_df.shape

"""now concatenate the string data with numerical data"""

thyroid_df = pd.concat([thyroid_df, numerical_col], axis=1)

thyroid_df.head()

# for shifting binaryClass in end column
binaryClass = thyroid_df.binaryClass
thyroid_df = thyroid_df.drop(columns='binaryClass')
thyroid_df = pd.concat([thyroid_df, binaryClass], axis=1)
print(thyroid_df.head())

thyroid_df.head()

#
#
#
#
#
#
#
#
#

#
#
#
#

"""here binaryClass is not string so make it string"""

thyroid_df.info()

thyroid_df.shape

"""Now"""

#for duplicates
thyroid_df = thyroid_df.drop_duplicates()
thyroid_df.info()

thyroid_df['age'] = pd.to_numeric(thyroid_df['age'], errors='coerce')

thyroid_df.age.dtype

#Handling missing values
thyroid_df.isnull().sum()

# Fill missing values in 'age' with the median of the age
median_value = thyroid_df['age'].median()
thyroid_df['age'] = thyroid_df['age'].fillna(median_value)

thyroid_df.isnull().sum()

thyroid_df.describe()

"""#Data standardization"""

X = thyroid_df.drop(columns='binaryClass')
Y = thyroid_df.binaryClass
print(X)
print(Y)

print(X.std())

scaler = StandardScaler()
x_standardizer = scaler.fit_transform(X)
X = x_standardizer

X.std()

print(X)

"""#**Handling Imbalance Dataset**"""

print(thyroid_df.shape)

print(thyroid_df.binaryClass.value_counts())

# no of 0 and 1 are unequal so make them equal   so we have to make 1 sample of 291 random values
zero = thyroid_df[thyroid_df.binaryClass==0]
one = thyroid_df[thyroid_df.binaryClass==1]

print(zero.shape, one.shape)

"""Undersampling"""

one_sample = one.sample(n=291)

print(zero.shape, one_sample.shape)

"""concatenate the two"""

new_dataset = pd.concat([zero, one_sample], axis=0)

new_dataset.shape

new_dataset.head()

#seperate feature and target
X = new_dataset.drop(columns=['binaryClass'], axis=1)
Y = new_dataset.binaryClass

"""#**Model Selection**

cross validation
"""

X = np.asarray(X)
Y = np.asarray(Y)

"""comparing the models with default hyperparameter values using cross validation

**stratified k-fold cross validation**
"""

#list of models
models = [LogisticRegression(max_iter=1000), SVC(kernel='linear'), KNeighborsClassifier(), RandomForestClassifier(random_state=1), XGBClassifier()]

def compare_models_cross_validation():
  for model in models:
    print(f'\nfor {model}--\n')
    cv_score = cross_val_score(model, X, Y, cv=5)
    print(cv_score)
    mean_accuracy = sum(cv_score)/len(cv_score)
    print('mean accuracy ', round(mean_accuracy * 100, 2))

compare_models_cross_validation()

"""Hence, for this dataset , XGBClassifier has the highest accuracy value with default hyperparameter values"""

#later on train test split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1)
model = RandomForestClassifier()
model.fit(X_train, Y_train)
# accuracy on training data
X_train_prediction = model.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)
print('Accuracy score on training data: ', training_data_accuracy*100, '%')
# accuracy on test data
X_test_prediction = model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)
print('Accuracy score on testing data: ', test_data_accuracy*100, '%')

"""for increasing accuracy more

#Hyperparameter tuning

comparing the models with different hyperparameter values using grid search cv
"""

#list of models
models_list = [LogisticRegression(max_iter=10000), SVC(), KNeighborsClassifier(), RandomForestClassifier(random_state=1), XGBClassifier()]

# creating a dictionary that contains hyperparameter values for the above mentioned models


model_hyperparameters = {


    'log_reg_hyperparameters': {

        'C' : [1,5,10,20]
    },

    'svc_hyperparameters': {

        'kernel' : ['linear','poly','rbf','sigmoid'],
        'C' : [1,5,10,20]
    },


    'KNN_hyperparameters' : {

        'n_neighbors' : [3,5,7, 9, 11]
    },


    'random_forest_hyperparameters' : {

        'n_estimators' : [10, 20, 50, 100]
    },

    'xgb_hyperparameters' : {
    'n_estimators': [50, 100, 200, 300],           # Number of boosting rounds
    'learning_rate': [0.01, 0.05, 0.1, 0.2],       # Step size shrinkage used to prevent overfitting
    }
}

model_keys = list(model_hyperparameters.keys())
model_keys

model_hyperparameters[model_keys[0]]

def grid_selection(list_of_models, model_hyperparameters):
  result=[]
  i = 0
  for model in list_of_models:
    key = model_keys[i]
    params = model_hyperparameters[key]
    i = i + 1
    print(model)
    print(params)
    print('**********************************')
    classifier = GridSearchCV(model, params, cv=5)
    classifier.fit(X, Y)
    result.append({
      'model used' : model,
      'highest score' : classifier.best_score_,
      'best hyperparameters' : classifier.best_params_
    })
    print(pd.DataFrame(classifier.cv_results_))
  result_dataframe = pd.DataFrame(result, columns = ['model used','highest score','best hyperparameters'])
  return result_dataframe

grid_selection(models_list, model_hyperparameters)

"""Hence, XGBClassifier has highest accuracy for learning_rate=0.01 and n_estimators=300

#**Now, Train test split**
"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)

"""#**Model Training**"""

model = XGBClassifier(learning_rate=0.01, n_estimators=300)

model.fit(X_train, Y_train)

"""#**Model Evaluation**"""

# accuracy on training data
X_train_prediction = model.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)
print('Accuracy score on training data: ', training_data_accuracy*100, '%')

# accuracy on test data
X_test_prediction = model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)
print('Accuracy score on testing data: ', test_data_accuracy*100, '%')

thyroid_df.head()

thyroid_df.shape

input_data = (1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,28.0,1.4,2.4,102.0,1.08,95.0)

#changing the input_data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)

# we need to reshape the numpy array as we predicting for one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)   # -1 represents that automatically decide the no of column  and the no of row is 1
prediction = model.predict(input_data_reshaped)
print(prediction)
if prediction[0]==0:
  print('Negative')
else:
  print('Positive')

